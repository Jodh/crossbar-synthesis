{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Synthesis of convolution layer on flowbased xbar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+KgE/kGLl1lLklpgxiYBZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jodh/crossbar-synthesis/blob/master/Synthesis_of_convolution_layer_on_flowbased_xbar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J3XN_5LdjaR"
      },
      "source": [
        "1. **Train and extract weights of a BNN for cifar-10**\n",
        "\n",
        "2.   **Generate constraints for SMT solving for a given kernel (from the BNN)**\n",
        "\n",
        "3.   **Solve the generated formula and map it to a crossbar**\n",
        "\n",
        "4.   **Test the crossbar on cifar-10 test set using python functions to simulate the crossbar and the other layers**\n",
        "\n",
        "5.   **The crossbar simulation function contains parameters to add errors**\n",
        "\n",
        "6.   **Test cifar-10 test set on standard multiply accumulate crossbars also simulated using similar python functions with parameters to add errors**\n",
        "\n",
        "Files needed: \n",
        "\n",
        "/content/cifar-10-bnn-model-30-80-10-weights.txt,\n",
        "\n",
        "/content/cifar-test-flat.npy, \n",
        " \n",
        "/content/cifar-testY-flat.npy \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKkAP-z4zFOZ"
      },
      "source": [
        "!pip install z3-solver\n",
        "!pip install lcapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHLtrZO9sNFo"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import re\n",
        "from lcapy import *\n",
        "import time\n",
        "import csv"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62qJud-riDl"
      },
      "source": [
        "**Helper Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVlXsSv2r56S"
      },
      "source": [
        "**Functions for generating the truth-table for a given kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoM1MhbLrabe"
      },
      "source": [
        "#helper functions       \n",
        "def _hard_sigmoid(x):\n",
        "    '''Hard sigmoid different from the more conventional form (see definition of K.hard_sigmoid).\n",
        "\n",
        "    # Reference:\n",
        "    - [BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, Courbariaux et al. 2016](http://arxiv.org/abs/1602.02830}\n",
        "\n",
        "    '''\n",
        "    x = (0.5 * x) + 0.5\n",
        "    return np.clip(x, 0, 1)\n",
        "\n",
        "def binary_tanh(x):\n",
        "    '''Binary hard sigmoid for training binarized neural network.\n",
        "     The neurons' activations binarization function\n",
        "     It behaves like the sign function during forward propagation\n",
        "     And like:\n",
        "        hard_tanh(x) = 2 * _hard_sigmoid(x) - 1 \n",
        "        clear gradient when |x| > 1 during back propagation\n",
        "\n",
        "    # Reference:\n",
        "    - [BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1, Courbariaux et al. 2016](http://arxiv.org/abs/1602.02830}\n",
        "\n",
        "    '''\n",
        "    return 2 * np.round(_hard_sigmoid(x)) - 1\n",
        "\n",
        "def batch_norm(x, weights):\n",
        "    mean = weights[2]\n",
        "    variance = weights[3]\n",
        "    beta = weights[1]\n",
        "    gamma = weights[0]\n",
        "    epsilon = 0.000001\n",
        "    y = (x-mean)/np.sqrt(variance+epsilon)\n",
        "    return gamma*y+beta\n",
        "\n",
        "def kernel_op(in_array,weights,parameters):\n",
        "    w = np.sign(weights)\n",
        "    conv2d_out = binary_tanh(batch_norm(np.dot(in_array,w),parameters))\n",
        "    return conv2d_out\n",
        " \n",
        "# take weights, dot product with input, normalize, acitvation function       \n",
        "def fill_tt_deci():\n",
        "    tt_deci = np.zeros((1,2),dtype=int)\n",
        "    for i in range(2**5):\n",
        "        tt_deci = np.append(tt_deci,np.array([[i,0]]),axis = 0)\n",
        "    return tt_deci[1:,]\n",
        "    \n",
        "def fill_tt(tt_deci,weights,kernel):\n",
        "    tt = np.zeros((2**5,6),dtype=bool)\n",
        "    in_pixels = np.zeros((1,5),dtype=bool)\n",
        "    w = weights[0][:,:,0,kernel][0]\n",
        "    parameters = np.array((weights[1][kernel],weights[2][kernel],weights[3][kernel],weights[4][kernel]))\n",
        "    # temp2 = np.zeros((1,13),dtype=bool)\n",
        "    for i in range(2**5):\n",
        "        in_pixels = (tt_deci[i,0] & (2**np.arange(5))>0)\n",
        "        conv2d_out = kernel_op(in_pixels,w,parameters)\n",
        "        if conv2d_out == -1:\n",
        "            conv2d_out = 0\n",
        "        tt[i,:] = np.append(in_pixels,conv2d_out)\n",
        "\n",
        "    return tt\n",
        "\n",
        "def generate_kernel_tt(kernel):\n",
        "    with open(\"cifar-10-bnn-model-30-80-10-weights.txt\", \"rb\") as fp:   # Unpickling\n",
        "        weights = pickle.load(fp)\n",
        "    tt_deci = fill_tt_deci()\n",
        "    tt = fill_tt(tt_deci, weights, kernel)\n",
        "    return tt"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXhyqUMZru23"
      },
      "source": [
        "**Functions for gnerating constraints for the z3 solver**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WbgZTR6rs1A"
      },
      "source": [
        "# declare variables\n",
        "def declare_variables():\n",
        "    code = '(declare-fun M (Int Int) Int)\\n'\n",
        "    code += '(declare-fun I (Int Int) Bool)\\n'\n",
        "    code += '(declare-fun O (Int Int) Bool)\\n'\n",
        "    code += '(declare-fun m (Int Int Int) Bool)\\n'\n",
        "    code += '(declare-fun row (Int Int Int) Bool)\\n'\n",
        "    code += '(declare-fun col (Int Int Int) Bool)\\n'\n",
        "    \n",
        "    return code\n",
        "\n",
        "# assign values to variables, read from I/O truth table\n",
        "def assign_values(n,m,input_size,truth_table,tt_size):\n",
        "    # assign input\n",
        "    code = '(assert (and\\n'\n",
        "    for k in range(tt_size):\n",
        "        for b in range(input_size):\n",
        "            code +=  '(= (I {k} {b}) {v})\\n'.format(k=k,b=b,v=str(truth_table[k,b]).lower())\n",
        "    # code += '\\n'\n",
        "    #assign output\n",
        "    for k in range(tt_size):\n",
        "        for b in range(1):\n",
        "            code += '(= (O {k} {b}) {v})\\n'.format(b=b,k=k,v=str(truth_table[k,b+input_size]).lower())\n",
        "    #assign row zero to true for each input-row\n",
        "    for k in range(tt_size):\n",
        "        code += '(row 0 0 {k})\\n'.format(k=k)\n",
        "    #assign rest of the rows and columns at time 0 to false, row_itk, col_jtk\n",
        "    for k in range(tt_size):\n",
        "        for i in range(1,n):\n",
        "            code += '(not (row {i} 0 {k}))\\n'.format(i=i,k=k)\n",
        "    for k in range(tt_size):\n",
        "        for j in range(m):\n",
        "            code += '(not (col {j} 0 {k}))\\n'.format(j=j,k=k)\n",
        "    code += '))\\n'\n",
        "    \n",
        "    return code\n",
        "\n",
        "#set range of memristor labels\n",
        "def set_range_of_mem_labels(n,m,input_size):\n",
        "    num_labels = 2*input_size+2\n",
        "    code = '(assert (and\\n'\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            code += '(>= (M {i} {j}) 0) (<= (M {i} {j}) {v})\\n'.format(i=i,j=j,v=num_labels-1)\n",
        "    code += '))\\n'\n",
        "    return code\n",
        "\n",
        "#set value of mijk\n",
        "def assign_mijk(n,m,input_size,tt_size):\n",
        "    code = '(assert (and\\n'\n",
        "    for k in range(tt_size):\n",
        "        for i in range(n):\n",
        "            for j in range(m):\n",
        "                code += '(or\\n'\n",
        "                code += '(and (= (M {i} {j}) 0) (= (m {i} {j} {k}) false))\\n'.format(i=i,j=j,k=k)\n",
        "                code += '(and (= (M {i} {j}) 1) (= (m {i} {j} {k}) true))\\n'.format(i=i,j=j,k=k)\n",
        "                for label in range(input_size):\n",
        "                    code += '(and (= (M {i} {j}) {labelPlus2}) (= (m {i} {j} {k}) (I {k} {label})))\\n'.format(i=i,j=j,k=k,label=label,labelPlus2 = label+2)\n",
        "                for not_label in range(input_size):\n",
        "                    code += '(and (= (M {i} {j}) {labelPlus2}) (= (m {i} {j} {k}) (not (I {k} {label}))))\\n'.format(i=i,j=j,k=k,label=not_label,labelPlus2 = not_label+2+input_size)\n",
        "                code += ')\\n'\n",
        "    code += '))\\n'\n",
        "    return code\n",
        "\n",
        "#set value of row and columns\n",
        "def set_row_col(n,m,tt_size):\n",
        "    time = n+m+1\n",
        "    code = '(assert (and\\n'\n",
        "    for k in range(tt_size):\n",
        "        for t in range(1,time):\n",
        "            for j in range(m):\n",
        "                code += '(= (col {j} {t} {k}) (or (col {j} {tminus1} {k})\\n'.format(j=j,k=k,t=t,tminus1=t-1)\n",
        "                for i in range(n):\n",
        "                    code += '(and (row {i} {tminus1} {k}) (m {i} {j} {k}))\\n'.format(i=i,j=j,tminus1=t-1,k=k)\n",
        "                code += '))\\n'\n",
        "            for i in range(n):\n",
        "                code += '(= (row {i} {t} {k}) (or (row {i} {tminus1} {k})\\n'.format(i=i,k=k,t=t,tminus1=t-1)\n",
        "                for j in range(m):\n",
        "                    code += '(and (col {j} {tminus1} {k}) (m {i} {j} {k}))\\n'.format(i=i,j=j,tminus1=t-1,k=k)\n",
        "                code += '))\\n'\n",
        "    code += '))\\n'\n",
        "    return code\n",
        "\n",
        "#check rowntk against output\n",
        "def check_output(n,m,tt_size):\n",
        "    code = '(assert (and\\n'\n",
        "    for k in range(tt_size):\n",
        "        code += '(= (row {r} {T} {k}) (O {k} 0))\\n'.format(r=n-1,T=n+m,k=k)\n",
        "    code += '))\\n'\n",
        "    return code\n",
        "# check solvability\n",
        "def footer(n,m):\n",
        "    code = '(check-sat)\\n'\n",
        "#    for i in range(n):\n",
        "#        for j in range(m):\n",
        "#            code += '(get-value ((M {i} {j})))'.format(i=i,j=j)\n",
        "    # code += '(get-model)\\n'\n",
        "    return code\n",
        "#debug-functions\n",
        "def print_stuff(n,m,tt_size):\n",
        "    code = ''\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            code += '(get-value ((M {i} {j})))\\n'.format(i=i,j=j)\n",
        "    for k in range(tt_size):\n",
        "        # for b in range(5):\n",
        "        code += '(get-value ((row {b} {T} {k})))\\n'.format(b=n-1,T=n+m,k=k)\n",
        "    return code\n",
        "\n",
        "#n=int(argn)\n",
        "#m=int(argm)\n",
        "#kernel = int(arg_kernel)\n",
        "\n",
        "def write_formula(n,m,kernel):\n",
        "    truth_table = generate_kernel_tt(kernel)\n",
        "    input_size = truth_table.shape[1]-1\n",
        "    tt_size = truth_table.shape[0]\n",
        "    filepath = 'formulas/'\n",
        "    filename = 'kernel-{n}x{m}-{b}.txt'.format(n=n,m=m,b = kernel)\n",
        "    with open(filepath+filename,'w') as writer:\n",
        "        writer.write(declare_variables())\n",
        "        writer.write(assign_values(n, m, input_size, truth_table, tt_size))\n",
        "        writer.write(set_range_of_mem_labels(n, m, input_size))\n",
        "        writer.write(assign_mijk(n, m, input_size, tt_size))\n",
        "        writer.write(set_row_col(n, m, tt_size))\n",
        "        writer.write(check_output(n, m, tt_size))\n",
        "        writer.write(footer(n,m))\n",
        "        writer.write(print_stuff(n, m, tt_size))\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KlZPoott3j5"
      },
      "source": [
        "**Create formulas and designs directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT3_NjMBt_dX"
      },
      "source": [
        "from pathlib import Path\n",
        "d = Path(\"/content/designs\")\n",
        "f = Path(\"/content/formulas\")\n",
        "if not(d.exists()):\n",
        "  !mkdir ./designs\n",
        "if not(f.exists()):\n",
        "  !mkdir ./formulas\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXEdfurNvS2u"
      },
      "source": [
        "**Generate fromulas and solve them for designs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHaDKIwBuQ3Q"
      },
      "source": [
        "# range is number of kernels in your convolution layer, 30 in our case.\n",
        "for kernel in range(30):\n",
        "#    truth_table = generate_kernel_tt(kernel)       \n",
        "    write_formula(5, 5,kernel)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gImou3DTv0NU",
        "outputId": "cf21bc2e-8e44-4b12-dad7-083ba2ea015c"
      },
      "source": [
        "n = 5\n",
        "m = 5\n",
        "path = '/content/'\n",
        "for i in range(30):\n",
        "    command = 'z3 {path}formulas/kernel-{n}x{m}-{i}.txt > {path}designs/design-kernel-{n}x{m}-{i}.txt'.format(i=i, n=n, m=m, path=path)\n",
        "#    command = 'z3 {path}formulas/kernel-{n}x{m}-{i}.txt'.format(i=i,n=n,m=m,path=path)\n",
        "    # os.system(command)\n",
        "    !{command}\n",
        "    print('kernel design {i} found...'.format(i=i))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kernel design 0 found...\n",
            "kernel design 1 found...\n",
            "kernel design 2 found...\n",
            "kernel design 3 found...\n",
            "kernel design 4 found...\n",
            "kernel design 5 found...\n",
            "kernel design 6 found...\n",
            "kernel design 7 found...\n",
            "kernel design 8 found...\n",
            "kernel design 9 found...\n",
            "kernel design 10 found...\n",
            "kernel design 11 found...\n",
            "kernel design 12 found...\n",
            "kernel design 13 found...\n",
            "kernel design 14 found...\n",
            "kernel design 15 found...\n",
            "kernel design 16 found...\n",
            "kernel design 17 found...\n",
            "kernel design 18 found...\n",
            "kernel design 19 found...\n",
            "kernel design 20 found...\n",
            "kernel design 21 found...\n",
            "kernel design 22 found...\n",
            "kernel design 23 found...\n",
            "kernel design 24 found...\n",
            "kernel design 25 found...\n",
            "kernel design 26 found...\n",
            "kernel design 27 found...\n",
            "kernel design 28 found...\n",
            "kernel design 29 found...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDiwF74x8h-f"
      },
      "source": [
        "**Functions for parsing design outputs from z3 and mapping to xbar and evaluatiing the xbar output** [work needed to check or improve the circuit simulation, can be replaced with a pspice simulation instead]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGg97AHNAVv5"
      },
      "source": [
        "def convert_file_to_matrix(filename,n,m):\n",
        "    matrix = np.zeros((n,m),dtype=int)\n",
        "    file = open(filename,'r')\n",
        "    lines = file.readlines()[1:]\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            line = n*i+j\n",
        "            x = re.search(\"\\(*M.{6}([\\w]{1,2})\\)*\", lines[line])\n",
        "            matrix[i,j] = int(x.group(1))\n",
        "    \n",
        "    return matrix\n",
        "\n",
        "def find_mem_states(D, d_input):\n",
        "#    t0 = time.time()\n",
        "    num_literals = 2*len(d_input)+2\n",
        "    mapping = np.zeros(num_literals, dtype='bool')\n",
        "    m = np.zeros(np.shape(D))\n",
        "    for i in range(num_literals):\n",
        "        if i <=1:\n",
        "            mapping[i] = i\n",
        "        elif i <= (len(d_input)+1):\n",
        "            mapping[i]=d_input[i-2]\n",
        "            mapping[i+len(d_input)] = not(d_input[i-2])\n",
        "    for i in range(len(D[:,1])):\n",
        "        for j in range(len(D[1,:])):\n",
        "            m[i,j] = mapping[D[i,j]]\n",
        "#    t1 = time.time()\n",
        "#    print('finding mem states',t1-t0)\n",
        "    return m\n",
        "\n",
        "def flow_at_outwire(mem_states):\n",
        "#    t0 = time.time()\n",
        "    n = len(mem_states[:,1])\n",
        "    l = len(mem_states[1,:])\n",
        "    r = np.zeros(n,dtype='bool')\n",
        "    r[0] = 1\n",
        "    c = np.zeros(l,dtype='bool')\n",
        "    # iteration through time\n",
        "    t = 0\n",
        "    while t <= 10:\n",
        "        for j in range(l):\n",
        "            for i in range(n):\n",
        "                c[j] = c[j] or (mem_states[i,j] and r[i])\n",
        "        for i in range(1,n):\n",
        "            for j in range(l):\n",
        "                r[i] = r[i] or (mem_states[i,j] and c[j])\n",
        "\n",
        "        t = t+1\n",
        "#    t1 = time.time()\n",
        "#    print('flow finding',t1-t0)\n",
        "\n",
        "    return r[4]\n",
        "\n",
        "def drift_error(resistor, min_err,max_err):\n",
        "    resistor = int(resistor)\n",
        "    res_max = 20000\n",
        "    min_err = res_max*min_err/100\n",
        "    max_err = res_max*max_err/100\n",
        "    noise = np.random.randint(0,max_err)\n",
        "    return resistor+noise\n",
        "\n",
        "def drift_error_mac(resistor, min_err,max_err):\n",
        "    noise = (max_err/100 - min_err/100) * np.random.random_sample() - (min_err/100)\n",
        "    return resistor+noise\n",
        "    \n",
        "    \n",
        "def flow_based(n,m,err):\n",
        "    total_missmatch = 0\n",
        "    name_prefix = '{n}x{m}-'.format(n=n,m=m)\n",
        "    for kernel in range(30):\n",
        "        truth_table = generate_kernel_tt(kernel)\n",
        "        kernel_name = 'designs/design-kernel-'+name_prefix+str(kernel)+'.txt'\n",
        "        D = convert_file_to_matrix(kernel_name,n,m)\n",
        "#        mem_state = find_mem_states(D, truth_table[1])\n",
        "        true_min = 1\n",
        "        false_max = 0\n",
        "        miss_matches = 0\n",
        "        \n",
        "        for row in range(2**5):\n",
        "\n",
        "#            for trial in range(100):\n",
        "            mem_state = find_mem_states(D, truth_table[row][:5])\n",
        "#            true_out = flow_at_outwire(mem_state)\n",
        "            true_out = truth_table[row,5]\n",
        "            for trial in range(1):\n",
        "                ckt = Circuit()\n",
        "                ckt.add('Vin r1 0 0.3')\n",
        "                for i in range(n):\n",
        "                    for j in range(m):\n",
        "#                        programming_err = np.random.random(1)\n",
        "                        if mem_state[i,j] == 1:\n",
        "                            resistor = '2000'\n",
        "                        else:\n",
        "                            resistor = '600000'\n",
        "                        code = 'R{i}{j} r{i} c{j} {v}'.format(i=i+1,j=j+1,v=drift_error(resistor,-err,err))\n",
        "#                        code = 'R{i}{j} r{i} c{j} {v}'.format(i=i+1,j=j+1,v=resistor)\n",
        "                        ckt.add(code)\n",
        "                ckt.add('Rout r{n} 0 100'.format(n=n))\n",
        "#                acc[row] += int(ckt.Rout.i.evaluate()>=0.00259)\n",
        "#            print(row, acc[row])\n",
        "                current = ckt.Rout.i.evaluate()\n",
        "#                print(current,true_out)\n",
        "                if (current >= 5.5e-6) != true_out:\n",
        "                    miss_matches +=1\n",
        "                if true_out:\n",
        "                    if true_min >  current:\n",
        "                        true_min = current\n",
        "                else:\n",
        "                    if false_max < current:\n",
        "                        false_max = current\n",
        "#                print(ckt.Rout.i.evaluate(), true_out)\n",
        "#        print(miss_matches)\n",
        "#        print(false_max,true_min)\n",
        "        total_missmatch += miss_matches\n",
        "    print(total_missmatch)\n",
        "    return '{res_err},{out_err}\\n'.format(res_err=err, out_err=total_missmatch*100/960)\n",
        "\n",
        "def batch_norm(x, weights):\n",
        "    mean = weights[2]\n",
        "    variance = weights[3]\n",
        "    beta = weights[1]\n",
        "    gamma = weights[0]\n",
        "    epsilon = 0.000001\n",
        "    y = (x-mean)/np.sqrt(variance+epsilon)\n",
        "    return gamma*y+beta\n",
        "\n",
        "def _hard_sigmoid(x):\n",
        "    x = (0.5 * x) + 0.5\n",
        "    return np.clip(x, 0, 1)\n",
        "\n",
        "def binary_tanh(x):\n",
        "    return 2 * np.round(_hard_sigmoid(x)) - 1\n",
        "\n",
        "def ADC(current):\n",
        "    current = 1000*current\n",
        "    A = 5.4\n",
        "    M = 11\n",
        "    value = (2/M)*round((M/2)*current)\n",
        "    return np.round(A*value)\n",
        "    \n",
        "def mac_based(err):\n",
        "    with open(\"cifar-10-bnn-model-30-80-10-weights.txt\", \"rb\") as fp:   # Unpickling\n",
        "        weights = pickle.load(fp)\n",
        "    total_missmatches = 0\n",
        "    \n",
        "    for kernel in range(30):\n",
        "        truth_table = generate_kernel_tt(kernel)\n",
        "        missmatches = 0\n",
        "        w = drift_error_mac(np.sign(drift_error_mac(weights[0][:,:,0,kernel][0],-err,err)), -err,err)\n",
        "#        w = np.sign(weights[0][:,:,0,kernel][0])\n",
        "        masking_array = np.where(w == 1, 1, 0)\n",
        "        masking_array2 = np.where(w == -1, 1, 0)\n",
        "#        print(w, masking_array, masking_array2)\n",
        "        parameters = np.array((weights[1][kernel],weights[2][kernel],weights[3][kernel],weights[4][kernel]))\n",
        "        \n",
        "        for row in range(2**5):\n",
        "            true_out = truth_table[row,5]\n",
        "            v = truth_table[row,0:5]*0.1\n",
        "#            v_real = truth_table[row,0:5]*1\n",
        "            v1 = v*masking_array\n",
        "            v2 = v*masking_array2\n",
        "#            print(v,v1,v2)\n",
        "            ckt = Circuit()\n",
        "            ckt2 = Circuit()\n",
        "\n",
        "            ckt.add('V0 r0 0 {v0}'.format(v0 = v1[0]))\n",
        "            ckt.add('V1 r1 0 {v1}'.format(v1 = v1[1]))\n",
        "            ckt.add('V2 r2 0 {v2}'.format(v2 = v1[2]))\n",
        "            ckt.add('V3 r3 0 {v3}'.format(v3 = v1[3]))\n",
        "            ckt.add('V4 r4 0 {v4}'.format(v4 = v1[4]))\n",
        "            for i in range(5):\n",
        "                ckt.add('R{i} r{i} plus 100'.format(i=i))\n",
        "            ckt.add('Rout plus 0 100')\n",
        "#            \n",
        "            ckt2.add('V0 r0 0 {v0}'.format(v0 = v2[0]))\n",
        "            ckt2.add('V1 r1 0 {v1}'.format(v1 = v2[1]))\n",
        "            ckt2.add('V2 r2 0 {v2}'.format(v2 = v2[2]))\n",
        "            ckt2.add('V3 r3 0 {v3}'.format(v3 = v2[3]))\n",
        "            ckt2.add('V4 r4 0 {v4}'.format(v4 = v2[4]))\n",
        "            for i in range(5):\n",
        "                ckt2.add('R{i} r{i} plus 100'.format(i=i))\n",
        "            ckt2.add('Rout plus 0 100')\n",
        "            total_current = ADC(ckt.Rout.i.evaluate()- ckt2.Rout.i.evaluate())\n",
        "#            out_bit = binary_tanh(batch_norm(np.dot(v_real,w),parameters))\n",
        "#            if out_bit == -1:\n",
        "#                out_bit = 0\n",
        "#            print(ADC(total_current))\n",
        "#            for i in range(5):\n",
        "#                if w[i] == 1:\n",
        "#                    current_pos += currents[i]\n",
        "#                else:\n",
        "#                    current_neg += currents[i]\n",
        "#            print(ckt_pos.Rout.i.evaluate(), ckt_neg.Rout.i.evaluate())\n",
        "#            total_current = (ckt_pos.Rout.i.evaluate() - 0.2*np.sum(truth_table[row,0:5]))\n",
        "#            print(ckt_pos.Rout.v.evaluate(), ckt_neg.Rout.v.evaluate())\n",
        "#            print(total_current,true_out)\n",
        "            mac_out = binary_tanh(batch_norm(total_current,parameters))\n",
        "            if mac_out == -1:\n",
        "                mac_out = 0\n",
        "##            print(round(total_current*1e5),mac_out, true_out)\n",
        "#            if out_bit != true_out:\n",
        "            if mac_out != true_out:\n",
        "                missmatches += 1\n",
        "##        print(missmatches)\n",
        "        total_missmatches += missmatches\n",
        "    print(total_missmatches)\n",
        "    return '{res_err},{out_err}\\n'.format(res_err=err, out_err=total_missmatches*100/960)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUGcTgtpAzyj"
      },
      "source": [
        "**Run the flow based and multiply accumulate models using the above functions on various drift values and store error rates**\n",
        "\n",
        "compares the output of the circuits with the output of the kernels using the BNN weight file\n",
        "\n",
        "these error rates are used as computational short-hand for simulating errors in the inference phase in the next code block. Saves time on actually simulating the circuit for every input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yG32Eg8A8Y0",
        "outputId": "412cd49f-20b2-43e8-feb5-9ddceb3eccf7"
      },
      "source": [
        "# drift_values = [1,2,3,4,5,6,7,8,9,10]\n",
        "drift_values = [1]\n",
        "\n",
        "with open('flow-error.csv','w') as file:\n",
        "   for i in drift_values:\n",
        "       file.write(flow_based(5,5,i))\n",
        "       print(i, 'done...')\n",
        "        \n",
        "with open('mac-error.csv','w') as file:\n",
        "    for i in drift_values:\n",
        "        file.write(mac_based(i))\n",
        "        print(i, 'done...')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n",
            "1 done...\n",
            "235\n",
            "1 done...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4pE_E6HHIUF"
      },
      "source": [
        "**Functions for testing accuracy of whole BNN model by replacing the convolution layer with above simulated circuits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GA5W97O6t1j"
      },
      "source": [
        "images = np.load('cifar-test-flat.npy')\n",
        "#helper functions       \n",
        "def drift_error(weights, a,b):\n",
        "#    noise = (b-a)*np.random.random_sample()-a\n",
        "#    weights = weights + np.multiply(weights,noise)/100\n",
        "    res_max = 0.5\n",
        "    a = res_max*a/100\n",
        "    b = res_max*b/100\n",
        "    noise = (b-a)*np.random.random_sample(np.shape(weights))-a\n",
        "    return weights+noise\n",
        "\n",
        "def drift_error_parameters(weights, a,b):\n",
        "    noise = (b-a)*np.random.random_sample(np.shape(weights))-a\n",
        "    weights = weights + np.multiply(weights,noise)/100\n",
        "#    res_max = 0.5\n",
        "#    a = res_max*a/100\n",
        "#    b = res_max*b/100\n",
        "#    noise = np.random.randint(a,b)\n",
        "    return weights\n",
        "\n",
        "#  KERNEL function input: image, weights[0:5], output: -1,+1 array of 30*200\n",
        "def conv2d_crossbar(image,num_kernels,weights):\n",
        "    window_size = 5\n",
        "    conv2d_out = np.zeros((image.shape[0],num_kernels))\n",
        "    #pad input\n",
        "    padded_image = np.zeros(image.shape[0]+4)\n",
        "    padded_image[2:image.shape[0]+2] = image\n",
        "    #for each kernel shift over windows and do convolution\n",
        "    for kernel in range(num_kernels):\n",
        "#        w = np.sign(weights[0][:,:,0,kernel][0])\n",
        "#        parameters = np.array((weights[1][kernel],weights[2][kernel],weights[3][kernel],weights[4][kernel]))\n",
        "        kernel_name = 'designs/design-kernel-'+str(kernel)+'.txt'\n",
        "        D = convert_file_to_matrix(kernel_name,5,5)\n",
        "        for i in range(image.shape[0]):\n",
        "#            conv2d_out[i,kernel] = binary_tanh(batch_norm(np.dot(padded_image[i:i+window_size],w),parameters))\n",
        "#            conv2d_out[kernel*image.shape[0]+i] = batch_norm(np.dot(padded_image[i:i+window_size],w),parameters)\n",
        "#            conv2d_out[i,kernel] = np.dot(padded_image[i:i+window_size],w)\n",
        "            \n",
        "            mem_states = find_mem_states(D, padded_image[i:i+window_size])\n",
        "            conv2d_out[i,kernel] = np.sign(flow_at_outwire(mem_states)-0.1) \n",
        "    return conv2d_out.reshape(num_kernels*image.shape[0])\n",
        "\n",
        "def conv2d(image,num_kernels,weights, error, err):\n",
        "    window_size = 5\n",
        "    conv2d_out = np.zeros((image.shape[0],num_kernels))\n",
        "    #pad input\n",
        "    padded_image = np.zeros(image.shape[0]+4)\n",
        "    padded_image[2:image.shape[0]+2] = image\n",
        "    #for each kernel shift over windows and do convolution\n",
        "    for kernel in range(num_kernels):\n",
        "        w = np.sign(weights[0][:,:,0,kernel][0])\n",
        "        parameters = np.array((weights[1][kernel],weights[2][kernel],weights[3][kernel],weights[4][kernel]))\n",
        "        for i in range(image.shape[0]):\n",
        "            out_bit = binary_tanh(batch_norm(np.dot(padded_image[i:i+window_size],w),parameters))\n",
        "            if np.random.random() < err/100 and error:\n",
        "                out_bit = -1*out_bit\n",
        "            conv2d_out[i,kernel] = out_bit\n",
        "#            conv2d_out[kernel*image.shape[0]+i] = batch_norm(np.dot(padded_image[i:i+window_size],w),parameters)\n",
        "#            conv2d_out[i,kernel] = np.dot(padded_image[i:i+window_size],w)\n",
        "    return conv2d_out.reshape(num_kernels*image.shape[0])\n",
        "\n",
        "def conv2d_MAC(image,num_kernels,weights, error, err_range):\n",
        "    window_size = 5\n",
        "    conv2d_out = np.zeros((image.shape[0],num_kernels))\n",
        "    #pad input\n",
        "    padded_image = np.zeros(image.shape[0]+4)\n",
        "    padded_image[2:image.shape[0]+2] = image\n",
        "    #for each kernel shift over windows and do convolution\n",
        "    for kernel in range(num_kernels):\n",
        "        w = drift_error(np.sign(weights[0][:,:,0,kernel][0]), -err_range,err_range)\n",
        "        parameters = drift_error_parameters(np.array((weights[1][kernel],weights[2][kernel],weights[3][kernel],weights[4][kernel])),-err_range,err_range)\n",
        "        for i in range(image.shape[0]):\n",
        "            out_bit = binary_tanh(batch_norm(np.dot(padded_image[i:i+window_size],w),parameters))\n",
        "            conv2d_out[i,kernel] = out_bit\n",
        "#            conv2d_out[kernel*image.shape[0]+i] = batch_norm(np.dot(padded_image[i:i+window_size],w),parameters)\n",
        "#            conv2d_out[i,kernel] = np.dot(padded_image[i:i+window_size],w)\n",
        "    return conv2d_out.reshape(num_kernels*image.shape[0])\n",
        "\n",
        "def conv2d_MAC_error_model(image,num_kernels,weights, error, err):\n",
        "    window_size = 5\n",
        "    conv2d_out = np.zeros((image.shape[0],num_kernels))\n",
        "    #pad input\n",
        "    padded_image = np.zeros(image.shape[0]+4)\n",
        "    padded_image[2:image.shape[0]+2] = image\n",
        "    #for each kernel shift over windows and do convolution\n",
        "    for kernel in range(num_kernels):\n",
        "        w = np.sign(weights[0][:,:,0,kernel][0])\n",
        "        parameters = np.array((weights[1][kernel],weights[2][kernel],weights[3][kernel],weights[4][kernel]))\n",
        "        for i in range(image.shape[0]):\n",
        "            out_bit = binary_tanh(batch_norm(np.dot(padded_image[i:i+window_size],w),parameters))\n",
        "            if np.random.random() < err/100 and error:\n",
        "                out_bit = -1*out_bit\n",
        "            conv2d_out[i,kernel] = out_bit\n",
        "#            conv2d_out[kernel*image.shape[0]+i] = batch_norm(np.dot(padded_image[i:i+window_size],w),parameters)\n",
        "#            conv2d_out[i,kernel] = np.dot(padded_image[i:i+window_size],w)\n",
        "    return conv2d_out.reshape(num_kernels*image.shape[0])\n",
        "\n",
        "# DENSE LAYER FUNCTIONS\n",
        "def dense_layer_exact_1(conv2d, num_nodes, weights, layer_num, err_range):\n",
        "    dense_out = np.zeros(num_nodes)\n",
        "    for node in range(num_nodes):\n",
        "        a = drift_error(binary_tanh(weights[layer_num][:,node]),-err_range,err_range)\n",
        "        parameters = drift_error_parameters(np.array((weights[layer_num+1][node],weights[layer_num+2][node],weights[layer_num+3][node],weights[layer_num+4][node])), -err_range,err_range)\n",
        "        dense_out[node] = binary_tanh(batch_norm(np.dot(conv2d,a),parameters))\n",
        "#        dense_out[node] = batch_norm(np.dot(conv2d,a),parameters)\n",
        "#        dense_out[node] = np.dot(conv2d,a)\n",
        "    return dense_out\n",
        "\n",
        "def dense_layer_exact_out(dense_1, num_nodes, weights, layer_num, err_range):\n",
        "    dense_out = np.zeros(num_nodes)\n",
        "    for node in range(num_nodes):\n",
        "        a = drift_error(binary_tanh(weights[layer_num][:,node]),-err_range,err_range)\n",
        "        parameters = drift_error_parameters(np.array((weights[layer_num+1][node],weights[layer_num+2][node],weights[layer_num+3][node],weights[layer_num+4][node])), -err_range, err_range)\n",
        "#        dense_out[node] = binary_tanh(batch_norm(np.dot(conv2d,a),parameters))\n",
        "        dense_out[node] = batch_norm(np.dot(dense_1,a),parameters)\n",
        "    return dense_out\n",
        "\n",
        "def classify_cifar(conv_kernels, dense_1_nodes, dense_2_nodes, err_row0, err_row1, hybrid=True):\n",
        "    matches = 0\n",
        "    with open(\"cifar-10-bnn-model-30-80-10-weights.txt\", \"rb\") as fp:   # Unpickling\n",
        "        weights = pickle.load(fp)\n",
        "    images = np.load('cifar-test-flat.npy')\n",
        "#    images = images[0:1000]\n",
        "    y_test = np.load('cifar-testY-flat.npy')\n",
        "#    t0 = time.time()\n",
        "    for i in range(500):\n",
        "#        conv2d_out = conv2d_crossbar(images[i],30,weights)\n",
        "        if hybrid:\n",
        "            conv2d_out = conv2d(images[i],30,weights,1, err_row1)\n",
        "        else:\n",
        "           conv2d_out = conv2d_MAC_error_model(images[i],30,weights,1, err_row0)\n",
        "            # conv2d_out = conv2d_MAC(images[i],30,weights,1, err_row0)\n",
        "        dense_1 = dense_layer_exact_1(conv2d_out, dense_1_nodes, weights, 5, 0)\n",
        "        dense_2 = dense_layer_exact_out(dense_1, dense_2_nodes, weights, 10, 0)\n",
        "        y_out = np.argmax(dense_2)\n",
        "        if np.argmax(y_test[i]) == y_out:\n",
        "            matches +=1\n",
        "#        if i % 1000 == 0:\n",
        "#            if i == 0:\n",
        "#                continue\n",
        "#            else:\n",
        "#                t1 = time.time()\n",
        "#                print(i,'image mark....',t1-t0)\n",
        "#                print(100*(matches/(i)))\n",
        "    print(err_row0,100*(matches/500))\n",
        "    return '{},{}\\n'.format(err_row0,100*(matches/500))\n",
        "\n",
        "\n",
        "def test_error_rates(hybrid):\n",
        "    out_string = ''\n",
        "    model_type = ''\n",
        "    if hybrid:\n",
        "      model_type = 'flow-error.csv'\n",
        "    else:\n",
        "      model_type = 'mac-error.csv'\n",
        "    with open(model_type, mode='r') as file:\n",
        "    # with open('flow-error.csv',mode = 'r') as file: #temp, comment out later\n",
        "        reader = csv.reader(file, delimiter=',')\n",
        "        for row in reader:            \n",
        "            out_string += classify_cifar(30, 80, 10, float(row[0]),float(row[1]),hybrid)\n",
        "    return out_string"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXmyefTGINVT"
      },
      "source": [
        "**Flow Based Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsN3ujlEIB1h",
        "outputId": "40560bf5-7a40-4f54-da9c-69063a4531ce"
      },
      "source": [
        "with open('drift-vs-hybrid-accuracy.csv','w') as file:\n",
        "    file.write(test_error_rates(True))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 88.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FddLwjOcIX6-"
      },
      "source": [
        "**Multiply Accumilate Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtIjV6CGIb84",
        "outputId": "3aaec57c-b580-45b8-c55d-039c95b17bbc"
      },
      "source": [
        "with open('drift-vs-mac-accuracy.csv','w') as file:\n",
        "    file.write(test_error_rates(False))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 92.0\n"
          ]
        }
      ]
    }
  ]
}